# VREC-dat-filter
Python script to filter .dat files using /v/'s Recommended Games Wiki

=========================================

VREC DAT Game Filter Script - User Manual

=========================================

== 1. Purpose ==

This Python script filters a game list file in DAT/XML format (like those used by ROM managers based on the Logiqx DTD, e.g., from redump.org) based on recommended game titles scraped from one or more specified web pages (e.g., wiki lists).

It works by:
1. Taking the base URL(s) you provide and automatically checking for corresponding `/Homebrew` and `/Japan` pages.
2. Fetching the recommended game titles from all existing/valid URLs found.
3. Parsing your input DAT file to get the game names.
4. Cleaning both the web titles and the DAT titles (removing common tags like (USA), [Europe], etc.).
5. Comparing the cleaned DAT titles against the cleaned web titles using fuzzy matching (specifically, the 'token_set_ratio' algorithm, which is good at handling extra words/subtitles) with a configurable similarity threshold.
6. Generating a new, filtered DAT file containing only the games that matched the web list criteria.
7. Generating separate CSV files for each source URL successfully processed, listing any recommended titles from that specific URL that were *not* found with sufficient similarity in your DAT file.
8. Displaying colored status messages, a progress bar, and a final summary report in the terminal.

== 2. Input File Recommendations (1G1R DATs) ==

For the best results with this script, it is highly recommended to use a "1 Game 1 ROM" (1G1R) style DAT file as your input.

What are 1G1R DATs?
--------------------
Standard DAT files from sources like Redump or No-Intro often list multiple versions of the same game (e.g., different regions like USA/Europe/Japan, revisions like Rev 1/Rev 2, betas, prototypes, demos, etc.). A 1G1R DAT file aims to include only one "best" or preferred version of each unique game, usually prioritizing your preferred region(s) and the latest official revision, removing most duplicates.

Why use 1G1R with this script?
-------------------------------
- Fewer Duplicates: Reduces the chance of multiple entries in your DAT file matching the same recommended title from the web lists. This makes the filtered output cleaner.
- Faster Processing: Filtering a smaller, curated DAT file is quicker than processing a large, comprehensive DAT with many redundant entries.
- Better Matching Focus: Comparing against a single, well-defined entry per game can improve the relevance of the matches found.

How to get 1G1R DATs?
---------------------
You typically create 1G1R DAT files yourself using ROM manager tools. These tools can filter comprehensive DAT files (like those from Redump or No-Intro) based on your preferences (regions, languages, removing clones, betas, demos, etc.). Some popular tools capable of this include:
- RomVault
- Romulus
- Retool (specifically designed for filtering/retooling DATs)
- ClrMamePro (more complex, often used for auditing and rebuilding sets)

Using a 1G1R DAT generated by one of these tools as the <INPUT_FILE> for this script is likely to produce the most useful and accurate filtered list based on the web recommendations.

== 3. Prerequisites ==

Before running the script, you need:

1.  Python 3: Version 3.8 or later is recommended.
    - Download from: https://www.python.org/downloads/windows/
    - IMPORTANT: During installation on Windows, make sure to check the box "Add Python X.Y to PATH".
    - Verify installation by opening Command Prompt (Cmd) or PowerShell and typing `python --version` and `pip --version`.

2.  Required Python Libraries:
    - These libraries are needed: `requests`, `beautifulsoup4`, `lxml`, `thefuzz`, `colorama`, `tqdm`.
    - The easiest way to install them is using the `requirements.txt` file method described in the Setup section below.

== 4. Setup ==

1.  Save the Script: Save the complete Python script code provided to you in a file named `filter_script.py` (or any name ending in `.py`).

2.  Create `requirements.txt`: In the SAME directory where you saved `filter_script.py`, create a new, plain text file named exactly `requirements.txt`. Paste the following lines into this file:

    requests
    beautifulsoup4
    lxml
    thefuzz
    colorama
    tqdm

3.  Install Dependencies: Open your terminal (Cmd or PowerShell), navigate to the directory containing the script and `requirements.txt` (using the `cd` command), and run:

    pip install -r requirements.txt

    This command will read the file and install all the necessary libraries. You only need to do this once for your Python environment (or each time you create a new virtual environment).

== 5. How to Run the Script ==

1.  Open your terminal (Command Prompt, PowerShell, Windows Terminal, etc.).
2.  Navigate to the directory where you saved `filter_script.py` and your input DAT file using the `cd` command.
    Example: `cd C:\Users\YourName\Scripts\DATFilter`
3.  Run the script using the following command structure:

    python filter_script.py <INPUT_FILE> [OUTPUT_FILE] --urls <URL1> [URL2...] [OPTIONS]

    - Replace `<INPUT_FILE>` with the path to your .dat file (preferably a 1G1R DAT, see Section 2). Can also be .xml/.txt containing XML.
    - `[OUTPUT_FILE]` is optional (see Arguments below).
    - Replace `<URL1> [URL2...]` with the *base* web page URL(s) containing the recommended titles (the script will auto-check for `/Homebrew` and `/Japan` variants).
    - `[OPTIONS]` are other optional flags like `--threshold`.
    - IMPORTANT: If any file path or URL contains spaces, enclose it in double quotes (`"`).

== 6. Command Line Arguments ==

* `<INPUT_FILE>` (Required)
    - The first argument after the script name.
    - Path to the input .dat file (or .xml/.txt containing XML) (required).
    - Example: `"Sony - PlayStation (1G1R).dat"`

* `[OUTPUT_FILE]` (Optional)
    - The second argument after the script name (if provided).
    - Path where the filtered output DAT file will be saved.
    - If omitted: A file named `<input_filename>_filtered.dat` will be created in the same directory as the input file.
    - Example: `"Filtered PSX Games.dat"`

* `--urls <URL1> [URL2...]` or `-u <URL1> [URL2...]` (Required)
    - Must be followed by one or more *base* web page URLs, separated by spaces.
    - These URLs point to the main pages containing the lists of recommended game titles.
    - Example: `--urls "https://wiki.example.com/wiki/PlayStation"`

    NOTE ON URLs & AUTO-EXPANSION: The source wikis for recommended games (like the V.Rec wiki referenced during development) have sometimes changed their domain names over the years. This script intentionally does *not* hardcode specific URLs. You *must* provide the current, correct *base* URL(s) using this argument.
    For each base URL provided (e.g., `.../wiki/SystemName`), the script will *automatically* also check for corresponding `/Homebrew` and `/Japan` pages (e.g., `.../wiki/SystemName/Homebrew` and `.../wiki/SystemName/Japan`). If these derived URLs exist and contain relevant tables, their titles will also be included in the filtering process. If they don't exist (404 Not Found), they will be silently ignored (you might see a dim info message). The script should continue to function correctly even if the main domain changes, provided you supply the updated base URL(s).

* `--threshold <0-100>` or `-t <0-100>` (Optional)
    - Sets the minimum similarity percentage (0-100) required for a match between a DAT title and a web title.
    - Default: `90`
    - Example: `--threshold 85`

* (Note: The `--csv_output` argument was removed, as CSV files are now generated automatically per URL).

== 7. Examples ==

* Basic usage with a 1G1R DAT (Checks .../PSX_Recommended, .../Homebrew, .../Japan automatically):
    python filter_script.py "Sony - PlayStation (1G1R).dat" --urls "https://wiki.example.com/wiki/PSX_Recommended"

* Specifying output DAT name, multiple systems (will check variants for both), 85% threshold:
    python filter_script.py "input/all_systems_1g1r.dat" "output/all_filtered.dat" --urls "https://wiki.example.com/wiki/PlayStation" "https://wiki.example.com/wiki/NES" -t 85

* Using short flags:
    python filter_script.py game_list_1g1r.dat -u "https://wiki.example.com/wiki/SNES"

== 8. Output Files ==

1.  Filtered DAT File:
    - Named either as specified by `[OUTPUT_FILE]` or `<input_filename>_filtered.dat`.
    - Created in the location specified or in the input file's directory.
    - Contains the original header and only the `<game>` entries from the input DAT that had a name matching (with >= threshold similarity using `token_set_ratio`) at least one title found on the specified web pages (including titles from `/Homebrew` and `/Japan` variants if found).

2.  Unmatched Titles CSV File(s):
    - One CSV file may be created for *each URL successfully processed* (including automatically checked `/Homebrew` and `/Japan` variants) *if* that URL contained recommended titles that did *not* find a match in your DAT file.
    - Location: Saved in the same directory as the filtered DAT file.
    - **Naming:** `<SystemName>_<Variant>_unmatched.csv` (e.g., `PlayStation_unmatched.csv`, `PlayStation_Homebrew_unmatched.csv`, `PlayStation_Japan_unmatched.csv`). The name is derived from the relevant parts of the URL path (after '/wiki/'), joined by underscores, and sanitized.
    - Content: A single column listing the recommended titles from that *specific URL* that were *not* found in your DAT file according to the matching criteria. This helps identify potential missing games or naming discrepancies for each source list.

== 9. Console Output ==

While running, the script will display:
- Status messages (fetching, parsing, filtering, writing) usually in cyan.
- Information about the URLs being checked (including the auto-expanded ones).
- Warnings in yellow and Errors in red (printed to stderr). 404 errors for non-existent auto-checked URLs are ignored or shown as dim info messages.
- A progress bar (`tqdm`) during the web fetching stage and the main filtering stage.
- A final summary report with colored results and aligned numbers, showing counts for total games, web titles found per URL, total unique web titles, matches found, non-matches, etc., and the matching algorithm used (`token_set_ratio`).

== 10. Origin and Acknowledgements ==

The initial idea for filtering DAT files based on the V.Rec wiki recommendations was inspired by rishooty's vrec-dat-filter script (https://github.com/rishooty/vrec-dat-filter).

However, this particular Python script is a complete rewrite from scratch. It was developed collaboratively with the assistance of Google Gemini (using an experimental version available around March 2025), as I did not have the necessary programming expertise to implement the desired features and iterative refinements independently.